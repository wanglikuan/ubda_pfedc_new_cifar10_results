2022-01-27 00:46:54:INFO:-------------Round number: 0-------------
2022-01-27 00:46:54:INFO:-------------Sending models-------------
2022-01-27 00:46:54:INFO:-------------Evaluating models-------------
2022-01-27 00:46:54:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:46:54:INFO:Accuracy = [0.9, 0.1, 0.1, 0.1, 0.881, 0.877, 0.1, 0.1, 0.9, 0.9]
2022-01-27 00:46:54:INFO:Loss = [0.6655188262462616, 0.7253304064273834, 0.7186193972826004, 0.7330755680799484, 0.6907198905944825, 0.6898890763521195, 0.739288130402565, 0.7035761296749115, 0.6848070502281189, 0.6382222563028336]
2022-01-27 00:46:54:INFO:-------------Training local models-------------
2022-01-27 01:01:26:INFO:-------------Aggregating local models-------------
2022-01-27 01:01:29:INFO:-------------Round number: 1-------------
2022-01-27 01:01:29:INFO:-------------Sending models-------------
2022-01-27 01:01:29:INFO:-------------Evaluating models-------------
2022-01-27 01:01:29:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:01:29:INFO:Accuracy = [0.904, 0.908, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9]
2022-01-27 01:01:29:INFO:Loss = [0.20869327752734534, 0.21127985524944962, 0.19745279218768702, 0.20001753843389453, 0.21580583918839694, 0.23073281246470287, 0.21170737909851595, 0.2057187751866877, 0.2266352892620489, 0.2228301422612276]
2022-01-27 01:01:29:INFO:-------------Training local models-------------
2022-01-27 01:16:21:INFO:-------------Aggregating local models-------------
2022-01-27 01:16:24:INFO:-------------Round number: 2-------------
2022-01-27 01:16:24:INFO:-------------Sending models-------------
2022-01-27 01:16:25:INFO:-------------Evaluating models-------------
2022-01-27 01:16:25:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:16:25:INFO:Accuracy = [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9]
2022-01-27 01:16:25:INFO:Loss = [0.1902750973647926, 0.18653623343270737, 0.18674810415250248, 0.18195398217940237, 0.1984861877601361, 0.20161344309453852, 0.18121841698011848, 0.1803034518874483, 0.19140570205636323, 0.18858528654673137]
2022-01-27 01:16:25:INFO:-------------Training local models-------------
2022-01-27 01:33:12:INFO:-------------Aggregating local models-------------
2022-01-27 01:33:15:INFO:-------------Round number: 3-------------
2022-01-27 01:33:15:INFO:-------------Sending models-------------
2022-01-27 01:33:15:INFO:-------------Evaluating models-------------
2022-01-27 01:33:16:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:33:16:INFO:Accuracy = [0.907, 0.907, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9]
2022-01-27 01:33:16:INFO:Loss = [0.18690383609646233, 0.18271483100397745, 0.18637418356956914, 0.18060507195768877, 0.2004400511214044, 0.20261082251672632, 0.17731797217566053, 0.17638400331197773, 0.18550430859031622, 0.18272825512394775]
2022-01-27 01:33:16:INFO:-------------Training local models-------------
2022-01-27 01:49:53:INFO:-------------Aggregating local models-------------
2022-01-27 01:49:56:INFO:-------------Round number: 4-------------
2022-01-27 01:49:56:INFO:-------------Sending models-------------
2022-01-27 01:49:56:INFO:-------------Evaluating models-------------
2022-01-27 01:49:57:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 01:49:57:INFO:Accuracy = [0.911, 0.913, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9]
2022-01-27 01:49:57:INFO:Loss = [0.183795035557705, 0.17978144609660376, 0.18881169886735732, 0.18293790463067125, 0.20103008901351133, 0.20309849673940333, 0.17258841498405672, 0.17140957372175764, 0.18079351718333783, 0.17845666803332277]
2022-01-27 01:49:57:INFO:-------------Training local models-------------
2022-01-27 02:06:35:INFO:-------------Aggregating local models-------------
2022-01-27 02:06:37:INFO:-------------Round number: 5-------------
2022-01-27 02:06:37:INFO:-------------Sending models-------------
2022-01-27 02:06:38:INFO:-------------Evaluating models-------------
2022-01-27 02:06:38:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:06:38:INFO:Accuracy = [0.913, 0.914, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9]
2022-01-27 02:06:38:INFO:Loss = [0.18051716108748223, 0.1766809682841995, 0.19234104955685324, 0.18764119247207417, 0.2000394682683691, 0.20225091424654237, 0.16684787437407067, 0.16564518678787862, 0.17613022947189166, 0.1742747180222068]
2022-01-27 02:06:38:INFO:-------------Training local models-------------
2022-01-27 02:23:17:INFO:-------------Aggregating local models-------------
2022-01-27 02:23:19:INFO:-------------Round number: 6-------------
2022-01-27 02:23:19:INFO:-------------Sending models-------------
2022-01-27 02:23:20:INFO:-------------Evaluating models-------------
2022-01-27 02:23:20:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:23:20:INFO:Accuracy = [0.92, 0.914, 0.9, 0.9, 0.9, 0.9, 0.901, 0.901, 0.9, 0.9]
2022-01-27 02:23:20:INFO:Loss = [0.17783577762020286, 0.17392299333878328, 0.19274785641755443, 0.18968099775811426, 0.197120710524905, 0.19949341316096253, 0.16447132433822845, 0.16345153271686286, 0.17418809885566588, 0.17281856146364588]
2022-01-27 02:23:20:INFO:-------------Training local models-------------
2022-01-27 02:40:03:INFO:-------------Aggregating local models-------------
2022-01-27 02:40:06:INFO:-------------Round number: 7-------------
2022-01-27 02:40:06:INFO:-------------Sending models-------------
2022-01-27 02:40:06:INFO:-------------Evaluating models-------------
2022-01-27 02:40:07:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:40:07:INFO:Accuracy = [0.92, 0.915, 0.9, 0.9, 0.902, 0.901, 0.902, 0.902, 0.9, 0.9]
2022-01-27 02:40:07:INFO:Loss = [0.1771900921667111, 0.1731906113032892, 0.1934551658530836, 0.19108747269492596, 0.19306293755435036, 0.19553156258625676, 0.16463280096504604, 0.16383760758471907, 0.17251889663893963, 0.1716835131883272]
2022-01-27 02:40:07:INFO:-------------Training local models-------------
2022-01-27 02:56:46:INFO:-------------Aggregating local models-------------
2022-01-27 02:56:49:INFO:-------------Round number: 8-------------
2022-01-27 02:56:49:INFO:-------------Sending models-------------
2022-01-27 02:56:49:INFO:-------------Evaluating models-------------
2022-01-27 02:56:50:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 02:56:50:INFO:Accuracy = [0.92, 0.914, 0.9, 0.9, 0.907, 0.906, 0.902, 0.903, 0.9, 0.9]
2022-01-27 02:56:50:INFO:Loss = [0.17853603691837633, 0.17465130826749373, 0.19544746175670297, 0.1931620498507982, 0.1898775874018611, 0.19248612960000172, 0.16737194689558238, 0.16680464147648308, 0.17337149110899192, 0.17290485230769265]
2022-01-27 02:56:50:INFO:-------------Training local models-------------
2022-01-27 03:13:21:INFO:-------------Aggregating local models-------------
2022-01-27 03:13:24:INFO:-------------Round number: 9-------------
2022-01-27 03:13:24:INFO:-------------Sending models-------------
2022-01-27 03:13:25:INFO:-------------Evaluating models-------------
2022-01-27 03:13:25:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 03:13:25:INFO:Accuracy = [0.921, 0.913, 0.901, 0.9, 0.907, 0.904, 0.905, 0.908, 0.9, 0.9]
2022-01-27 03:13:25:INFO:Loss = [0.18085250983276638, 0.1772542150454683, 0.19514656919127446, 0.19280630224238848, 0.1872280950559798, 0.19025840607864666, 0.1719153702226322, 0.171540652593103, 0.17381945067281776, 0.17351954026817112]
2022-01-27 03:13:25:INFO:-------------Training local models-------------
2022-01-27 03:29:53:INFO:-------------Aggregating local models-------------
2022-01-27 03:29:56:INFO:-------------Round number: 10-------------
2022-01-27 03:29:56:INFO:-------------Sending models-------------
2022-01-27 03:29:56:INFO:-------------Evaluating models-------------
2022-01-27 03:29:57:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 03:29:57:INFO:Accuracy = [0.919, 0.916, 0.909, 0.907, 0.911, 0.908, 0.912, 0.915, 0.915, 0.909]
2022-01-27 03:29:57:INFO:Loss = [0.18496214432925626, 0.18174284357301076, 0.193653891129361, 0.19139850365027086, 0.1850257230376883, 0.18817088910509483, 0.178470598018248, 0.1783372886304278, 0.17266179737962375, 0.17255099233661894]
2022-01-27 03:29:57:INFO:-------------Training local models-------------
2022-01-27 03:46:24:INFO:-------------Aggregating local models-------------
2022-01-27 03:46:27:INFO:-------------Round number: 11-------------
2022-01-27 03:46:27:INFO:-------------Sending models-------------
2022-01-27 03:46:28:INFO:-------------Evaluating models-------------
2022-01-27 03:46:28:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 03:46:28:INFO:Accuracy = [0.919, 0.92, 0.915, 0.911, 0.913, 0.912, 0.916, 0.918, 0.927, 0.924]
2022-01-27 03:46:28:INFO:Loss = [0.19091900466228254, 0.1881239435115276, 0.19294471055618487, 0.19087004630928278, 0.18353006832876417, 0.18635304396411811, 0.18584462079197692, 0.18587031354181818, 0.1714741384716035, 0.17134649154795625]
2022-01-27 03:46:28:INFO:-------------Training local models-------------
2022-01-27 04:02:56:INFO:-------------Aggregating local models-------------
2022-01-27 04:02:58:INFO:-------------Round number: 12-------------
2022-01-27 04:02:58:INFO:-------------Sending models-------------
2022-01-27 04:02:59:INFO:-------------Evaluating models-------------
2022-01-27 04:02:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 04:02:59:INFO:Accuracy = [0.92, 0.919, 0.914, 0.912, 0.918, 0.915, 0.92, 0.921, 0.929, 0.928]
2022-01-27 04:02:59:INFO:Loss = [0.20024624934667373, 0.19775855022926409, 0.19398482367541875, 0.1920001737526036, 0.18372948745654866, 0.1856976015653345, 0.19250080937945313, 0.19263490776356776, 0.17241967991431012, 0.1722021466865044]
2022-01-27 04:02:59:INFO:-------------Training local models-------------
2022-01-27 04:19:27:INFO:-------------Aggregating local models-------------
2022-01-27 04:19:30:INFO:-------------Round number: 13-------------
2022-01-27 04:19:30:INFO:-------------Sending models-------------
2022-01-27 04:19:30:INFO:-------------Evaluating models-------------
2022-01-27 04:19:31:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 04:19:31:INFO:Accuracy = [0.918, 0.919, 0.917, 0.913, 0.922, 0.921, 0.922, 0.925, 0.927, 0.928]
2022-01-27 04:19:31:INFO:Loss = [0.2115829946969825, 0.20915893562123528, 0.19694412424141775, 0.19506383916013875, 0.18738350109997554, 0.18802140553143545, 0.19567533382742114, 0.19584569632188503, 0.1758622796391137, 0.17556125899245673]
2022-01-27 04:19:31:INFO:-------------Training local models-------------
2022-01-27 04:35:59:INFO:-------------Aggregating local models-------------
2022-01-27 04:36:02:INFO:-------------Round number: 14-------------
2022-01-27 04:36:02:INFO:-------------Sending models-------------
2022-01-27 04:36:02:INFO:-------------Evaluating models-------------
2022-01-27 04:36:03:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 04:36:03:INFO:Accuracy = [0.916, 0.917, 0.921, 0.919, 0.926, 0.921, 0.926, 0.926, 0.928, 0.927]
2022-01-27 04:36:03:INFO:Loss = [0.22178159101240452, 0.21933578021908035, 0.20037765452543682, 0.19865775815051165, 0.19596586551288056, 0.19505094174510304, 0.19685252506824327, 0.19720997592939965, 0.1803177888161372, 0.17999188363501162]
2022-01-27 04:36:03:INFO:-------------Training local models-------------
2022-01-27 04:52:30:INFO:-------------Aggregating local models-------------
2022-01-27 04:52:33:INFO:-------------Round number: 15-------------
2022-01-27 04:52:33:INFO:-------------Sending models-------------
2022-01-27 04:52:33:INFO:-------------Evaluating models-------------
2022-01-27 04:52:34:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 04:52:34:INFO:Accuracy = [0.916, 0.918, 0.923, 0.922, 0.923, 0.922, 0.927, 0.931, 0.931, 0.928]
2022-01-27 04:52:34:INFO:Loss = [0.23140040429098008, 0.22893791332098773, 0.20275083701963012, 0.20126225880594575, 0.20734865284775877, 0.2052318409023428, 0.19760979536404194, 0.19809469607462232, 0.1843511556760859, 0.18392430931944545]
2022-01-27 04:52:34:INFO:-------------Training local models-------------
2022-01-27 05:09:02:INFO:-------------Aggregating local models-------------
2022-01-27 05:09:04:INFO:-------------Round number: 16-------------
2022-01-27 05:09:04:INFO:-------------Sending models-------------
2022-01-27 05:09:05:INFO:-------------Evaluating models-------------
2022-01-27 05:09:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 05:09:05:INFO:Accuracy = [0.919, 0.919, 0.925, 0.924, 0.92, 0.92, 0.932, 0.933, 0.933, 0.934]
2022-01-27 05:09:05:INFO:Loss = [0.2404555856944171, 0.23784441965890438, 0.20376798387187592, 0.2025292842190538, 0.22141413965309767, 0.21836767167442303, 0.19694547868566586, 0.19750039696155, 0.18741680339635422, 0.18690151970513397]
2022-01-27 05:09:05:INFO:-------------Training local models-------------
2022-01-27 05:25:33:INFO:-------------Aggregating local models-------------
2022-01-27 05:25:35:INFO:-------------Round number: 17-------------
2022-01-27 05:25:35:INFO:-------------Sending models-------------
2022-01-27 05:25:36:INFO:-------------Evaluating models-------------
2022-01-27 05:25:36:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 05:25:36:INFO:Accuracy = [0.919, 0.919, 0.929, 0.926, 0.92, 0.92, 0.933, 0.933, 0.932, 0.931]
2022-01-27 05:25:36:INFO:Loss = [0.24876425601605662, 0.24592193109856453, 0.20365730090579745, 0.2027144280360517, 0.23440374655638152, 0.23084871341125107, 0.19560168028065164, 0.19618126571131142, 0.1897429076330809, 0.18916862326514092]
2022-01-27 05:25:36:INFO:-------------Training local models-------------
2022-01-27 05:42:05:INFO:-------------Aggregating local models-------------
2022-01-27 05:42:08:INFO:-------------Round number: 18-------------
2022-01-27 05:42:08:INFO:-------------Sending models-------------
2022-01-27 05:42:08:INFO:-------------Evaluating models-------------
2022-01-27 05:42:09:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 05:42:09:INFO:Accuracy = [0.92, 0.92, 0.935, 0.929, 0.922, 0.92, 0.936, 0.935, 0.93, 0.93]
2022-01-27 05:42:09:INFO:Loss = [0.2566154934801489, 0.2535210183192248, 0.20233281520304444, 0.20178457415786397, 0.24516414758500105, 0.24130548216035094, 0.19395796260423595, 0.19456065894173663, 0.19136221209701035, 0.19073162502209015]
2022-01-27 05:42:09:INFO:-------------Training local models-------------
2022-01-27 05:58:37:INFO:-------------Aggregating local models-------------
2022-01-27 05:58:39:INFO:-------------Round number: 19-------------
2022-01-27 05:58:39:INFO:-------------Sending models-------------
2022-01-27 05:58:40:INFO:-------------Evaluating models-------------
2022-01-27 05:58:40:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 05:58:40:INFO:Accuracy = [0.92, 0.919, 0.939, 0.93, 0.923, 0.921, 0.935, 0.935, 0.931, 0.929]
2022-01-27 05:58:40:INFO:Loss = [0.26386289067850155, 0.2605082450413647, 0.2002910954555773, 0.20014454749125435, 0.252194063017032, 0.24832050718332538, 0.19342247706790658, 0.19414552741254737, 0.19343929225578904, 0.19278252757476366]
2022-01-27 05:58:40:INFO:-------------Training local models-------------
2022-01-27 06:15:09:INFO:-------------Aggregating local models-------------
2022-01-27 06:15:11:INFO:-------------Round number: 20-------------
2022-01-27 06:15:11:INFO:-------------Sending models-------------
2022-01-27 06:15:12:INFO:-------------Evaluating models-------------
2022-01-27 06:15:12:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 06:15:12:INFO:Accuracy = [0.921, 0.921, 0.939, 0.934, 0.926, 0.925, 0.935, 0.935, 0.93, 0.931]
2022-01-27 06:15:12:INFO:Loss = [0.27137410352415825, 0.26777966075642323, 0.19800223507791087, 0.19815150457579875, 0.25644614163047663, 0.2526190196724201, 0.1936464012180295, 0.19451503893733388, 0.19610865598669988, 0.19544281433582]
2022-01-27 06:15:12:INFO:-------------Training local models-------------
2022-01-27 06:27:22:INFO:-------------Aggregating local models-------------
2022-01-27 06:27:24:INFO:-------------Round number: 21-------------
2022-01-27 06:27:24:INFO:-------------Sending models-------------
2022-01-27 06:27:24:INFO:-------------Evaluating models-------------
2022-01-27 06:27:24:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 06:27:24:INFO:Accuracy = [0.921, 0.921, 0.943, 0.941, 0.924, 0.922, 0.936, 0.935, 0.931, 0.931]
2022-01-27 06:27:24:INFO:Loss = [0.2783924145474884, 0.2745815776488598, 0.19533064986990212, 0.19574665781892692, 0.26164670087491687, 0.2576389008318074, 0.19332946542945137, 0.194330191424433, 0.19897662946905256, 0.1983448593182402]
2022-01-27 06:27:24:INFO:-------------Training local models-------------
2022-01-27 06:39:11:INFO:-------------Aggregating local models-------------
2022-01-27 06:39:13:INFO:-------------Round number: 22-------------
2022-01-27 06:39:13:INFO:-------------Sending models-------------
2022-01-27 06:39:13:INFO:-------------Evaluating models-------------
2022-01-27 06:39:14:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 06:39:14:INFO:Accuracy = [0.919, 0.919, 0.945, 0.944, 0.924, 0.924, 0.937, 0.935, 0.932, 0.932]
2022-01-27 06:39:14:INFO:Loss = [0.28533681840872305, 0.2812729765705626, 0.19260300622117937, 0.19305133032630692, 0.2665783560023556, 0.26245359457298034, 0.1925628613425033, 0.19363895655615124, 0.20181661412871107, 0.20121032578381345]
2022-01-27 06:39:14:INFO:-------------Training local models-------------
2022-01-27 06:51:00:INFO:-------------Aggregating local models-------------
2022-01-27 06:51:02:INFO:-------------Round number: 23-------------
2022-01-27 06:51:02:INFO:-------------Sending models-------------
2022-01-27 06:51:02:INFO:-------------Evaluating models-------------
2022-01-27 06:51:03:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 06:51:03:INFO:Accuracy = [0.92, 0.919, 0.947, 0.948, 0.925, 0.923, 0.935, 0.935, 0.934, 0.933]
2022-01-27 06:51:03:INFO:Loss = [0.29204261329514336, 0.2877270310692438, 0.19004474754019612, 0.1901840901500691, 0.27164511102673716, 0.26740383180849675, 0.19241512566686653, 0.19354765458583642, 0.20441485941291831, 0.20384242979125702]
2022-01-27 06:51:03:INFO:-------------Training local models-------------
2022-01-27 07:02:49:INFO:-------------Aggregating local models-------------
2022-01-27 07:02:51:INFO:-------------Round number: 24-------------
2022-01-27 07:02:51:INFO:-------------Sending models-------------
2022-01-27 07:02:51:INFO:-------------Evaluating models-------------
2022-01-27 07:02:52:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 07:02:52:INFO:Accuracy = [0.922, 0.92, 0.947, 0.947, 0.925, 0.924, 0.935, 0.935, 0.935, 0.934]
2022-01-27 07:02:52:INFO:Loss = [0.2988209741073661, 0.29427517503045236, 0.18789130747882155, 0.18775631142798374, 0.2768495708519822, 0.27256474128407715, 0.19207179089435159, 0.19326022323120923, 0.20682825250942188, 0.2063005525446897]
2022-01-27 07:02:52:INFO:-------------Training local models-------------
2022-01-27 07:14:39:INFO:-------------Aggregating local models-------------
2022-01-27 07:14:41:INFO:-------------Round number: 25-------------
2022-01-27 07:14:41:INFO:-------------Sending models-------------
2022-01-27 07:14:41:INFO:-------------Evaluating models-------------
2022-01-27 07:14:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 07:14:42:INFO:Accuracy = [0.922, 0.92, 0.949, 0.946, 0.925, 0.925, 0.936, 0.934, 0.936, 0.935]
2022-01-27 07:14:42:INFO:Loss = [0.30586168112122325, 0.3011300166580895, 0.18630173126966837, 0.18571313871107123, 0.2816582232848305, 0.27741380987608866, 0.19215308770826595, 0.19338195051823276, 0.20909960603289618, 0.20860956644255566]
2022-01-27 07:14:42:INFO:-------------Training local models-------------
2022-01-27 07:23:54:INFO:-------------Aggregating local models-------------
2022-01-27 07:23:55:INFO:-------------Round number: 26-------------
2022-01-27 07:23:55:INFO:-------------Sending models-------------
2022-01-27 07:23:56:INFO:-------------Evaluating models-------------
2022-01-27 07:23:56:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 07:23:56:INFO:Accuracy = [0.922, 0.92, 0.951, 0.949, 0.925, 0.924, 0.935, 0.935, 0.936, 0.936]
2022-01-27 07:23:56:INFO:Loss = [0.31264483357053907, 0.3077194896188303, 0.18541003005502715, 0.18423819978679604, 0.2862779112311273, 0.2820672215549166, 0.19243110002412323, 0.1936916878302327, 0.21112273607081988, 0.2106604080307079]
2022-01-27 07:23:56:INFO:-------------Training local models-------------
2022-01-27 07:31:53:INFO:-------------Aggregating local models-------------
2022-01-27 07:31:55:INFO:-------------Round number: 27-------------
2022-01-27 07:31:55:INFO:-------------Sending models-------------
2022-01-27 07:31:55:INFO:-------------Evaluating models-------------
2022-01-27 07:31:55:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 07:31:55:INFO:Accuracy = [0.922, 0.921, 0.95, 0.95, 0.925, 0.925, 0.937, 0.94, 0.937, 0.937]
2022-01-27 07:31:55:INFO:Loss = [0.3192574669275018, 0.3141763733784956, 0.18514252786826546, 0.1835748396748386, 0.2905664159741718, 0.28639533326231686, 0.19361344470094083, 0.1949148828862235, 0.21294242328258406, 0.21249956275178192]
2022-01-27 07:31:55:INFO:-------------Training local models-------------
2022-01-27 07:39:55:INFO:-------------Aggregating local models-------------
2022-01-27 07:39:56:INFO:-------------Round number: 28-------------
2022-01-27 07:39:56:INFO:-------------Sending models-------------
2022-01-27 07:39:56:INFO:-------------Evaluating models-------------
2022-01-27 07:39:56:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 07:39:56:INFO:Accuracy = [0.922, 0.922, 0.951, 0.95, 0.924, 0.925, 0.94, 0.941, 0.937, 0.937]
2022-01-27 07:39:56:INFO:Loss = [0.32561310801202126, 0.32036153895055575, 0.18544412866149287, 0.18334231999242548, 0.29458842502581317, 0.29045750636760204, 0.19503582196089156, 0.1963794730239897, 0.2146620218435146, 0.2142382097556947]
2022-01-27 07:39:56:INFO:-------------Training local models-------------
2022-01-27 07:47:35:INFO:-------------Aggregating local models-------------
2022-01-27 07:47:37:INFO:-------------Round number: 29-------------
2022-01-27 07:47:37:INFO:-------------Sending models-------------
2022-01-27 07:47:37:INFO:-------------Evaluating models-------------
2022-01-27 07:47:37:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 07:47:37:INFO:Accuracy = [0.923, 0.921, 0.949, 0.949, 0.924, 0.925, 0.942, 0.942, 0.937, 0.937]
2022-01-27 07:47:37:INFO:Loss = [0.33146734526649196, 0.32605307697731406, 0.18596293262289693, 0.18366198234471084, 0.29823439825627246, 0.2941570501793649, 0.19660898475958674, 0.19797209874268445, 0.21633727476851164, 0.21592490486204952]
2022-01-27 07:47:37:INFO:-------------Training local models-------------
2022-01-27 07:56:20:INFO:-------------Aggregating local models-------------
