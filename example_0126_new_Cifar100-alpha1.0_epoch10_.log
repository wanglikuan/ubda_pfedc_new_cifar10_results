2022-01-26 17:38:47:INFO:-------------Round number: 0-------------
2022-01-26 17:38:47:INFO:-------------Sending models-------------
2022-01-26 17:38:47:INFO:-------------Evaluating models-------------
2022-01-26 17:38:48:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 17:38:48:INFO:Accuracy = [0.8998401704848162, 0.09922749067661162, 0.1001598295151838, 0.09909429941395845, 0.8790623335109217, 0.8826584976025573, 0.10042621204049014, 0.09962706446457112, 0.8991742141715503, 0.8994405966968567]
2022-01-26 17:38:48:INFO:Loss = [0.6655192559204904, 0.7253744506381837, 0.7186372587511879, 0.7332048017370872, 0.6907839094490591, 0.6898970211844655, 0.7393671502267419, 0.7035915054535701, 0.6847794067370618, 0.638321891172998]
2022-01-26 17:38:48:INFO:-------------Training local models-------------
2022-01-26 17:55:31:INFO:-------------Aggregating local models-------------
2022-01-26 17:55:37:INFO:-------------Round number: 1-------------
2022-01-26 17:55:37:INFO:-------------Sending models-------------
2022-01-26 17:55:37:INFO:-------------Evaluating models-------------
2022-01-26 17:55:39:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 17:55:39:INFO:Accuracy = [0.8998401704848162, 0.9007725093233884, 0.8998401704848162, 0.9009057005860416, 0.898907831646244, 0.9011720831113479, 0.8995737879595098, 0.9003729355354289, 0.8991742141715503, 0.8994405966968567]
2022-01-26 17:55:39:INFO:Loss = [0.2905355180491141, 0.29139161947196707, 0.2943793966935538, 0.2845550286596007, 0.2743299234389056, 0.29285664091727237, 0.2919720705493403, 0.2921607540831065, 0.2903467138696285, 0.3025091284380895]
2022-01-26 17:55:39:INFO:-------------Training local models-------------
2022-01-26 18:12:23:INFO:-------------Aggregating local models-------------
2022-01-26 18:12:28:INFO:-------------Round number: 2-------------
2022-01-26 18:12:28:INFO:-------------Sending models-------------
2022-01-26 18:12:29:INFO:-------------Evaluating models-------------
2022-01-26 18:12:30:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 18:12:30:INFO:Accuracy = [0.8998401704848162, 0.9007725093233884, 0.9003729355354289, 0.9009057005860416, 0.8993074054342035, 0.9011720831113479, 0.8995737879595098, 0.9003729355354289, 0.8991742141715503, 0.8994405966968567]
2022-01-26 18:12:30:INFO:Loss = [0.2864530965146005, 0.28835800774084114, 0.28289008569061663, 0.27790686282164034, 0.26256077092902047, 0.2794262985215107, 0.2859760208425524, 0.2786976191713626, 0.28085353243183075, 0.29622232661814246]
2022-01-26 18:12:30:INFO:-------------Training local models-------------
2022-01-26 18:29:14:INFO:-------------Aggregating local models-------------
2022-01-26 18:29:20:INFO:-------------Round number: 3-------------
2022-01-26 18:29:20:INFO:-------------Sending models-------------
2022-01-26 18:29:20:INFO:-------------Evaluating models-------------
2022-01-26 18:29:21:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 18:29:21:INFO:Accuracy = [0.8998401704848162, 0.9007725093233884, 0.9054342035162494, 0.9009057005860416, 0.9045018646776771, 0.9011720831113479, 0.8995737879595098, 0.9003729355354289, 0.8991742141715503, 0.8994405966968567]
2022-01-26 18:29:21:INFO:Loss = [0.27931314080528874, 0.287231695239388, 0.27167306543557596, 0.2751072950423762, 0.25080981996363416, 0.27573217651258497, 0.28278897690984184, 0.2742988132682148, 0.2771561864176026, 0.28740840154061403]
2022-01-26 18:29:21:INFO:-------------Training local models-------------
2022-01-26 18:45:58:INFO:-------------Aggregating local models-------------
2022-01-26 18:46:03:INFO:-------------Round number: 4-------------
2022-01-26 18:46:03:INFO:-------------Sending models-------------
2022-01-26 18:46:04:INFO:-------------Evaluating models-------------
2022-01-26 18:46:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 18:46:05:INFO:Accuracy = [0.9025039957378796, 0.9007725093233884, 0.9080980287693128, 0.9017048481619606, 0.9061001598295152, 0.9011720831113479, 0.8995737879595098, 0.9005061267980821, 0.8991742141715503, 0.9046350559403303]
2022-01-26 18:46:05:INFO:Loss = [0.2694257756186075, 0.2847336588977746, 0.257640241626918, 0.27271564182570845, 0.2400035526588327, 0.27257901869618, 0.27850600569243517, 0.27035214043146455, 0.27405841688223115, 0.2757966043799719]
2022-01-26 18:46:05:INFO:-------------Training local models-------------
2022-01-26 19:02:37:INFO:-------------Aggregating local models-------------
2022-01-26 19:02:42:INFO:-------------Round number: 5-------------
2022-01-26 19:02:42:INFO:-------------Sending models-------------
2022-01-26 19:02:43:INFO:-------------Evaluating models-------------
2022-01-26 19:02:44:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 19:02:44:INFO:Accuracy = [0.9070324986680873, 0.9007725093233884, 0.9123601491742142, 0.9017048481619606, 0.9090303676078849, 0.9011720831113479, 0.9006393180607352, 0.9007725093233884, 0.8991742141715503, 0.9070324986680873]
2022-01-26 19:02:44:INFO:Loss = [0.26104569575239767, 0.2813648665375642, 0.24541614954516125, 0.2706518626900749, 0.23244233228089847, 0.2696689854581435, 0.2740639522254912, 0.26584476986846634, 0.2709137872595799, 0.2660745120516516]
2022-01-26 19:02:44:INFO:-------------Training local models-------------
2022-01-26 19:19:15:INFO:-------------Aggregating local models-------------
2022-01-26 19:19:20:INFO:-------------Round number: 6-------------
2022-01-26 19:19:20:INFO:-------------Sending models-------------
2022-01-26 19:19:20:INFO:-------------Evaluating models-------------
2022-01-26 19:19:21:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 19:19:21:INFO:Accuracy = [0.9071656899307405, 0.9015716568993074, 0.9144912093766648, 0.9014384656366542, 0.9090303676078849, 0.9011720831113479, 0.9030367607884923, 0.9033031433137986, 0.8993074054342035, 0.9072988811933937]
2022-01-26 19:19:21:INFO:Loss = [0.25562909512731485, 0.2781557435180422, 0.23563237721621436, 0.2686812522160656, 0.22734914188951524, 0.2674257158761726, 0.2698656800116194, 0.2612413381590182, 0.2675406739118692, 0.25814009293294615]
2022-01-26 19:19:21:INFO:-------------Training local models-------------
2022-01-26 19:35:53:INFO:-------------Aggregating local models-------------
2022-01-26 19:35:58:INFO:-------------Round number: 7-------------
2022-01-26 19:35:58:INFO:-------------Sending models-------------
2022-01-26 19:35:59:INFO:-------------Evaluating models-------------
2022-01-26 19:36:00:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 19:36:00:INFO:Accuracy = [0.9058337773042089, 0.9018380394246137, 0.9167554608417687, 0.9013052743740011, 0.9100958977091103, 0.9011720831113479, 0.9047682472029834, 0.9066329248801278, 0.9014384656366542, 0.9078316462440064]
2022-01-26 19:36:00:INFO:Loss = [0.2519408615100603, 0.275369115291519, 0.227503905722799, 0.26676577255993783, 0.2241266833178051, 0.26571790780450355, 0.2659569311620083, 0.2568542519832076, 0.2639675016614688, 0.25073466245154463]
2022-01-26 19:36:00:INFO:-------------Training local models-------------
2022-01-26 19:52:31:INFO:-------------Aggregating local models-------------
2022-01-26 19:52:36:INFO:-------------Round number: 8-------------
2022-01-26 19:52:36:INFO:-------------Sending models-------------
2022-01-26 19:52:37:INFO:-------------Evaluating models-------------
2022-01-26 19:52:38:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 19:52:38:INFO:Accuracy = [0.9047682472029834, 0.9033031433137986, 0.9191529035695258, 0.9017048481619606, 0.9110282365476825, 0.9017048481619606, 0.9066329248801278, 0.9104954714970698, 0.9031699520511455, 0.9088971763452317]
2022-01-26 19:52:38:INFO:Loss = [0.24888919899016856, 0.2723305834019775, 0.21994031496349967, 0.2649664627989423, 0.22168596013932657, 0.26405478996578474, 0.26198262222444657, 0.25265261264103966, 0.26010913546924014, 0.24354170599419447]
2022-01-26 19:52:38:INFO:-------------Training local models-------------
2022-01-26 20:09:09:INFO:-------------Aggregating local models-------------
2022-01-26 20:09:15:INFO:-------------Round number: 9-------------
2022-01-26 20:09:15:INFO:-------------Sending models-------------
2022-01-26 20:09:15:INFO:-------------Evaluating models-------------
2022-01-26 20:09:16:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:09:16:INFO:Accuracy = [0.9049014384656366, 0.904368673415024, 0.9218167288225892, 0.9021044219499201, 0.9123601491742142, 0.9023708044752264, 0.9076984549813533, 0.9115610015982951, 0.9046350559403303, 0.9111614278103356]
2022-01-26 20:09:16:INFO:Loss = [0.2466286300201729, 0.2690522981981468, 0.21323867052144505, 0.26320642102853337, 0.21961092549150676, 0.2618535967845396, 0.2579272007718523, 0.24882635858819036, 0.25612463612659186, 0.2366156595737758]
2022-01-26 20:09:16:INFO:-------------Training local models-------------
2022-01-26 20:25:48:INFO:-------------Aggregating local models-------------
2022-01-26 20:25:53:INFO:-------------Round number: 10-------------
2022-01-26 20:25:53:INFO:-------------Sending models-------------
2022-01-26 20:25:54:INFO:-------------Evaluating models-------------
2022-01-26 20:25:55:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:25:55:INFO:Accuracy = [0.9057005860415557, 0.9054342035162494, 0.9250133191262653, 0.902770378263186, 0.9134256792754395, 0.9041022908897176, 0.9100958977091103, 0.91302610548748, 0.9062333510921684, 0.9139584443260522]
2022-01-26 20:25:55:INFO:Loss = [0.24508090277059033, 0.265771949495291, 0.20764316233509103, 0.26146868156077174, 0.2176527271825487, 0.2593784934020421, 0.2538868425732511, 0.24547788878503, 0.25177282032189163, 0.23017166905426636]
2022-01-26 20:25:55:INFO:-------------Training local models-------------
2022-01-26 20:42:27:INFO:-------------Aggregating local models-------------
2022-01-26 20:42:32:INFO:-------------Round number: 11-------------
2022-01-26 20:42:32:INFO:-------------Sending models-------------
2022-01-26 20:42:33:INFO:-------------Evaluating models-------------
2022-01-26 20:42:33:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:42:33:INFO:Accuracy = [0.9050346297282899, 0.905966968566862, 0.9259456579648375, 0.9045018646776771, 0.9144912093766648, 0.905966968566862, 0.912226957911561, 0.9128929142248269, 0.9087639850825786, 0.9170218433670752]
2022-01-26 20:42:33:INFO:Loss = [0.24382465924089203, 0.262524030046655, 0.20301359119543733, 0.25979617869245886, 0.2158655653530052, 0.25705014974187484, 0.24985698779889115, 0.2429421809254013, 0.24723101024241542, 0.22442333757496286]
2022-01-26 20:42:33:INFO:-------------Training local models-------------
2022-01-26 20:59:04:INFO:-------------Aggregating local models-------------
2022-01-26 20:59:10:INFO:-------------Round number: 12-------------
2022-01-26 20:59:10:INFO:-------------Sending models-------------
2022-01-26 20:59:10:INFO:-------------Evaluating models-------------
2022-01-26 20:59:11:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 20:59:11:INFO:Accuracy = [0.9062333510921684, 0.9072988811933937, 0.9266116142781033, 0.9047682472029834, 0.9160895045285029, 0.9063665423548215, 0.9134256792754395, 0.9150239744272776, 0.9096963239211507, 0.9190197123068726]
2022-01-26 20:59:11:INFO:Loss = [0.24264732638416642, 0.2591834083916491, 0.1988637251635546, 0.25796612243329126, 0.21401101564127628, 0.25500249606321507, 0.24604002369560807, 0.24112435880092123, 0.24277038070470983, 0.21926615703067026]
2022-01-26 20:59:11:INFO:-------------Training local models-------------
2022-01-26 21:15:43:INFO:-------------Aggregating local models-------------
2022-01-26 21:15:49:INFO:-------------Round number: 13-------------
2022-01-26 21:15:49:INFO:-------------Sending models-------------
2022-01-26 21:15:49:INFO:-------------Evaluating models-------------
2022-01-26 21:15:50:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:15:50:INFO:Accuracy = [0.9070324986680873, 0.9095631326584976, 0.9279435269046351, 0.9054342035162494, 0.9158231220031966, 0.9071656899307405, 0.9151571656899308, 0.9151571656899308, 0.9108950452850293, 0.9222163026105488]
2022-01-26 21:15:50:INFO:Loss = [0.24158373286428608, 0.2559925764069351, 0.1952127824404977, 0.2559651894094446, 0.21240403774414227, 0.2533505074607906, 0.24280771096800163, 0.2401195627615779, 0.23871265820757975, 0.21449783038135598]
2022-01-26 21:15:50:INFO:-------------Training local models-------------
2022-01-26 21:32:21:INFO:-------------Aggregating local models-------------
2022-01-26 21:32:27:INFO:-------------Round number: 14-------------
2022-01-26 21:32:27:INFO:-------------Sending models-------------
2022-01-26 21:32:27:INFO:-------------Evaluating models-------------
2022-01-26 21:32:28:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:32:28:INFO:Accuracy = [0.9079648375066596, 0.9108950452850293, 0.9290090570058605, 0.9068993074054342, 0.9174214171550347, 0.9078316462440064, 0.9150239744272776, 0.9155567394778903, 0.912226957911561, 0.9232818327117741]
2022-01-26 21:32:28:INFO:Loss = [0.24038350127526242, 0.2531587125084636, 0.19214707951532298, 0.2538505485077451, 0.21078527319258314, 0.25202841257833275, 0.24039653111318673, 0.2395558873230922, 0.23510064202776107, 0.2107477611904298]
2022-01-26 21:32:28:INFO:-------------Training local models-------------
2022-01-26 21:49:00:INFO:-------------Aggregating local models-------------
2022-01-26 21:49:05:INFO:-------------Round number: 15-------------
2022-01-26 21:49:05:INFO:-------------Sending models-------------
2022-01-26 21:49:06:INFO:-------------Evaluating models-------------
2022-01-26 21:49:07:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 21:49:07:INFO:Accuracy = [0.9078316462440064, 0.9111614278103356, 0.9295418220564731, 0.9078316462440064, 0.9168886521044219, 0.9087639850825786, 0.9155567394778903, 0.9174214171550347, 0.9127597229621737, 0.9239477890250399]
2022-01-26 21:49:07:INFO:Loss = [0.23925884742117112, 0.2508842394659, 0.18961409234913681, 0.25179451406963077, 0.20905788977191692, 0.2509119671992223, 0.23867573199637898, 0.23878523999547632, 0.2320662359922894, 0.2074617073470781]
2022-01-26 21:49:07:INFO:-------------Training local models-------------
2022-01-26 22:05:38:INFO:-------------Aggregating local models-------------
2022-01-26 22:05:43:INFO:-------------Round number: 16-------------
2022-01-26 22:05:43:INFO:-------------Sending models-------------
2022-01-26 22:05:43:INFO:-------------Evaluating models-------------
2022-01-26 22:05:44:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:05:44:INFO:Accuracy = [0.9083644112946191, 0.9115610015982951, 0.9296750133191263, 0.9087639850825786, 0.917687799680341, 0.9091635588705381, 0.9163558870538092, 0.9166222695791156, 0.9126265316995205, 0.9262120404901438]
2022-01-26 22:05:44:INFO:Loss = [0.23816416910455052, 0.24904267864749477, 0.18744362539080353, 0.2497541792133331, 0.20738385498517387, 0.25006857799955573, 0.23744098802251454, 0.23865611680888954, 0.22942782340588155, 0.20470066810970491]
2022-01-26 22:05:44:INFO:-------------Training local models-------------
2022-01-26 22:22:16:INFO:-------------Aggregating local models-------------
2022-01-26 22:22:22:INFO:-------------Round number: 17-------------
2022-01-26 22:22:22:INFO:-------------Sending models-------------
2022-01-26 22:22:22:INFO:-------------Evaluating models-------------
2022-01-26 22:22:23:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:22:23:INFO:Accuracy = [0.9083644112946191, 0.9126265316995205, 0.9312733084709643, 0.9096963239211507, 0.9195524773574854, 0.9088971763452317, 0.9166222695791156, 0.9167554608417687, 0.9136920618007459, 0.9268779968034097]
2022-01-26 22:22:23:INFO:Loss = [0.2372856493731668, 0.24749451339967615, 0.18561054568551183, 0.24781620152708075, 0.2060791281416065, 0.24941752762764446, 0.2368060535496745, 0.23972307824347425, 0.22733910894244672, 0.2028054173437399]
2022-01-26 22:22:23:INFO:-------------Training local models-------------
2022-01-26 22:38:54:INFO:-------------Aggregating local models-------------
2022-01-26 22:39:00:INFO:-------------Round number: 18-------------
2022-01-26 22:39:00:INFO:-------------Sending models-------------
2022-01-26 22:39:00:INFO:-------------Evaluating models-------------
2022-01-26 22:39:01:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:39:01:INFO:Accuracy = [0.9075652637187, 0.9127597229621737, 0.9330047948854555, 0.9100958977091103, 0.9196856686201386, 0.9096963239211507, 0.9175546084176878, 0.9166222695791156, 0.9148907831646244, 0.9267448055407566]
2022-01-26 22:39:01:INFO:Loss = [0.2366012924618237, 0.24626517647069623, 0.18439177925200795, 0.24610325856036053, 0.20524082002300073, 0.24889012198492322, 0.2365682716409442, 0.24114285729640733, 0.22621630626042424, 0.20113388582573857]
2022-01-26 22:39:01:INFO:-------------Training local models-------------
2022-01-26 22:55:33:INFO:-------------Aggregating local models-------------
2022-01-26 22:55:38:INFO:-------------Round number: 19-------------
2022-01-26 22:55:38:INFO:-------------Sending models-------------
2022-01-26 22:55:39:INFO:-------------Evaluating models-------------
2022-01-26 22:55:40:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 22:55:40:INFO:Accuracy = [0.9082312200319659, 0.912226957911561, 0.9338039424613745, 0.910628662759723, 0.921683537559936, 0.9087639850825786, 0.9182205647309537, 0.9168886521044219, 0.9147575919019713, 0.9272775705913692]
2022-01-26 22:55:40:INFO:Loss = [0.2360577598237966, 0.2454133884407323, 0.1835403267659354, 0.24450688200861553, 0.2045257129516903, 0.24854925310995368, 0.23687373574517498, 0.24350559983909706, 0.22559082977023207, 0.19953946980261222]
2022-01-26 22:55:40:INFO:-------------Training local models-------------
2022-01-26 23:12:11:INFO:-------------Aggregating local models-------------
2022-01-26 23:12:16:INFO:-------------Round number: 20-------------
2022-01-26 23:12:16:INFO:-------------Sending models-------------
2022-01-26 23:12:16:INFO:-------------Evaluating models-------------
2022-01-26 23:12:17:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 23:12:17:INFO:Accuracy = [0.9083644112946191, 0.9126265316995205, 0.9340703249866809, 0.9120937666489078, 0.9211507725093234, 0.9087639850825786, 0.9180873734683005, 0.9168886521044219, 0.9143580181140117, 0.9280767181672882]
2022-01-26 23:12:17:INFO:Loss = [0.23604614914186026, 0.2449436260197018, 0.18327278170891437, 0.2432047028344975, 0.20404077364455192, 0.24845159623189395, 0.23726915745545907, 0.2460220608464771, 0.22558115013628469, 0.19818821197279396]
2022-01-26 23:12:17:INFO:-------------Training local models-------------
2022-01-26 23:28:50:INFO:-------------Aggregating local models-------------
2022-01-26 23:28:55:INFO:-------------Round number: 21-------------
2022-01-26 23:28:55:INFO:-------------Sending models-------------
2022-01-26 23:28:56:INFO:-------------Evaluating models-------------
2022-01-26 23:28:57:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 23:28:57:INFO:Accuracy = [0.9095631326584976, 0.91302610548748, 0.9332711774107618, 0.9124933404368674, 0.9211507725093234, 0.9082312200319659, 0.9186201385189131, 0.9158231220031966, 0.9147575919019713, 0.9291422482685135]
2022-01-26 23:28:57:INFO:Loss = [0.23610664367651965, 0.2449258598002514, 0.1833045279257869, 0.2420931378886091, 0.20383327746424318, 0.24860827891939044, 0.23789693406779572, 0.2489803181231955, 0.22595745111038124, 0.19699933498772332]
2022-01-26 23:28:57:INFO:-------------Training local models-------------
2022-01-26 23:45:27:INFO:-------------Aggregating local models-------------
2022-01-26 23:45:33:INFO:-------------Round number: 22-------------
2022-01-26 23:45:33:INFO:-------------Sending models-------------
2022-01-26 23:45:33:INFO:-------------Evaluating models-------------
2022-01-26 23:45:34:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-26 23:45:34:INFO:Accuracy = [0.9092967501331912, 0.913825253063399, 0.9330047948854555, 0.9135588705380927, 0.9211507725093234, 0.9087639850825786, 0.9190197123068726, 0.9158231220031966, 0.9151571656899308, 0.9299413958444326]
2022-01-26 23:45:34:INFO:Loss = [0.23707408584916312, 0.24533306133190216, 0.18377650396170994, 0.24136515805701136, 0.20380120504593285, 0.24906644652501844, 0.23853310207862627, 0.251926237480432, 0.22672426277056107, 0.1958624287679609]
2022-01-26 23:45:34:INFO:-------------Training local models-------------
2022-01-27 00:02:06:INFO:-------------Aggregating local models-------------
2022-01-27 00:02:11:INFO:-------------Round number: 23-------------
2022-01-27 00:02:11:INFO:-------------Sending models-------------
2022-01-27 00:02:12:INFO:-------------Evaluating models-------------
2022-01-27 00:02:13:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:02:13:INFO:Accuracy = [0.9086307938199254, 0.9143580181140117, 0.9332711774107618, 0.9134256792754395, 0.9227490676611614, 0.9084976025572722, 0.91848694725626, 0.9159563132658498, 0.914624400639318, 0.9304741608950453]
2022-01-27 00:02:13:INFO:Loss = [0.23848550716195738, 0.24622865287278425, 0.18472717312146247, 0.24104795100782775, 0.2044250697044375, 0.25002997811064004, 0.23939305840265532, 0.2554260762039345, 0.22789500833657206, 0.19520060584786633]
2022-01-27 00:02:13:INFO:-------------Training local models-------------
2022-01-27 00:18:44:INFO:-------------Aggregating local models-------------
2022-01-27 00:18:49:INFO:-------------Round number: 24-------------
2022-01-27 00:18:49:INFO:-------------Sending models-------------
2022-01-27 00:18:50:INFO:-------------Evaluating models-------------
2022-01-27 00:18:51:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-27 00:18:51:INFO:Accuracy = [0.9083644112946191, 0.9142248268513585, 0.9336707511987213, 0.9142248268513585, 0.9223494938732019, 0.9075652637187, 0.9178209909429942, 0.9160895045285029, 0.9143580181140117, 0.9311401172083111]
2022-01-27 00:18:51:INFO:Loss = [0.24002183580916964, 0.24759566533143046, 0.18587866376194315, 0.24098616516542337, 0.20514924112401856, 0.25146393360546254, 0.24017129510543847, 0.25839930981050524, 0.2294096202486863, 0.19435808940785135]
2022-01-27 00:18:51:INFO:-------------Training local models-------------
